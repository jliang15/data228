{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2eded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent cleaned data to topic 'test' at 2023-11-10 16:17:06\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 16:22:06\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 16:27:06\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 16:32:06\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 16:37:06\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 16:42:06\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 16:47:06\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 16:52:06\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 16:57:07\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 17:02:07\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 17:07:07\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 17:12:07\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 17:17:07\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 17:22:07\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 17:27:07\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 17:32:07\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 17:37:07\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 17:42:08\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 17:47:08\n",
      "Sent cleaned data to topic 'test' at 2023-11-10 17:52:08\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaProducer\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Kafka Producer Configuration\n",
    "producer = KafkaProducer(bootstrap_servers=['localhost:9092'],\n",
    "                         value_serializer=lambda x: x.encode('utf-8'))\n",
    "\n",
    "# Topic to send messages to\n",
    "topic = 'test'\n",
    "\n",
    "# URL of the data source\n",
    "url = \"https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt\"\n",
    "\n",
    "# List of headers for the DataFrame\n",
    "headers = [\n",
    "    'STN', 'LAT', 'LON', 'YYYY', 'MM', 'DD', 'hh', 'mm', 'WDIR', \n",
    "    'WSPD', 'GST', 'WVHT', 'DPD', 'APD', \n",
    "    'MWD', 'PRES', 'PTDY', 'ATMP', \n",
    "    'WTMP', 'DEWP', 'VIS', 'TIDE'\n",
    "]\n",
    "\n",
    "# List of station IDs to filter by\n",
    "station_ids = [\n",
    "    '46011', '46013', '46014', '46022', '46025', '46026', '46027', \n",
    "    '46028', '46042', '46053', '46054', '46069', '46086'\n",
    "]\n",
    "\n",
    "def fetch_and_clean_data(url, headers, station_ids):\n",
    "    # Fetch the data\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching data: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    # Read the content of the response into a Pandas DataFrame\n",
    "    data = pd.read_csv(StringIO(response.text), delim_whitespace=True, comment='#', names=headers, header=None)\n",
    "\n",
    "    # Convert the 'STN' to string and filter based on the station IDs list\n",
    "    data['STN'] = data['STN'].astype(str)\n",
    "    data = data[data['STN'].isin(station_ids)]\n",
    "    \n",
    "    data.replace('MM', np.nan, inplace=True)\n",
    "\n",
    "    # Ensure columns that should be numeric are of numeric type\n",
    "    for col in [\"WDIR\", \"WSPD\", \"GST\", \"PRES\", \"ATMP\"]:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "    # Impute missing values with the median of each column\n",
    "    for column in data.columns:\n",
    "        # Skip non-numeric columns\n",
    "        if data[column].dtype == float or data[column].dtype == int:\n",
    "            median = data[column].median()\n",
    "            if pd.notnull(median):  # Check if median is not NaN\n",
    "                data[column].fillna(median, inplace=True)\n",
    "\n",
    "    # Drop the original date and time columns\n",
    "    data.drop(['STN', 'LAT', 'LON', 'YYYY', 'MM', 'DD', 'hh', 'mm', \n",
    "               'WVHT', 'DPD', 'APD', 'MWD', 'PTDY', 'WTMP', 'DEWP', 'VIS', 'TIDE'], axis=1, inplace=True)\n",
    "\n",
    "    # Convert the cleaned DataFrame to a JSON string to send to Kafka\n",
    "    return data.to_json(orient='records', lines=True)\n",
    "\n",
    "# Producer loop\n",
    "try:\n",
    "    while True:\n",
    "        clean_data = fetch_and_clean_data(url, headers, station_ids)\n",
    "        if clean_data:\n",
    "            for record in clean_data.splitlines():\n",
    "                # Get the current time\n",
    "                current_time = datetime.now()\n",
    "                # Send message\n",
    "                producer.send(topic, value=record)\n",
    "            producer.flush()  # Ensure data is sent to Kafka promptly\n",
    "            print(f\"Sent cleaned data to topic '{topic}' at {current_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        else:\n",
    "            print(\"No data to send or there was an error fetching the data.\")\n",
    "        time.sleep(300)  # Wait for 5 minutes before fetching again\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped fetching data.\")\n",
    "finally:\n",
    "    producer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17819cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
